{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m-TNzMAhGeA",
        "outputId": "4950a325-8b03-4e92-8f5f-c9b31b6c2002"
      },
      "outputs": [],
      "source": [
        "# !pip install spektral\n",
        "# !pip install tensorflow_probability\n",
        "# !pip uninstall -y tensorflow\n",
        "# !pip install --user tensorflow==2.14.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5mQxzpZPZ7q"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow_probability import distributions as tfd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import tensorflow as tf\n",
        "from spektral.layers import ChebConv, GCNConv\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input, Concatenate, TimeDistributed, Conv1D, LayerNormalization\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXwo3OsQQvnb",
        "outputId": "20148c4d-d5c1-4149-e7df-4ae767ba33c5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def read_all_csv(folder_path):\n",
        "    all_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "    all_data = pd.DataFrame()\n",
        "\n",
        "    for file in all_files:\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        df = pd.read_csv(file_path)\n",
        "        all_data = all_data.append(df, ignore_index=True)\n",
        "\n",
        "    return all_data\n",
        "\n",
        "# Replace 'your_folder_path' with the path to your folder containing CSV files\n",
        "folder_path = '/metrics'\n",
        "df = read_all_csv(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTajyBqeQCOj",
        "outputId": "08a33d3b-0dc0-43f4-ee0b-42717a074d8f"
      },
      "outputs": [],
      "source": [
        "df.columns,df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGW88Ur_Q4fV"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns='Unnamed: 0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f_a1yg2Q8IP"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df[['providerrpc_rt',\n",
        "       'providerrpc_mcr', 'consumerrpc_rt', 'consumerrpc_mcr', 'writemc_rt',\n",
        "       'writemc_mcr', 'readmc_rt', 'readmc_mcr', 'writedb_rt', 'writedb_mcr',\n",
        "       'readdb_rt', 'readdb_mcr', 'consumermq_rt', 'consumermq_mcr',\n",
        "       'providermq_rt', 'providermq_mcr', 'http_mcr', 'http_rt',\n",
        "       'cpu_utilization', 'memory_utilization']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v61YhXBPQ9WT",
        "outputId": "210e4f08-257d-4948-9225-aa9699ff2d8b"
      },
      "outputs": [],
      "source": [
        "len(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FQ7K2tHRkdS",
        "outputId": "84d9d805-1ede-4a29-83b6-9e70616db027"
      },
      "outputs": [],
      "source": [
        "class CPUUtilizationEstimator:\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        # Input layer\n",
        "        inputs = Input(shape=(self.input_dim,))\n",
        "\n",
        "        # Shared fully-connected layers\n",
        "        x = Dense(self.hidden_dim, activation='relu')(inputs)\n",
        "\n",
        "        # Separate branches for mean and variance\n",
        "        mean = Dense(1, activation='linear')(x)\n",
        "        variance = Dense(1, activation='softplus')(x)  # softplus ensures variance is positive\n",
        "\n",
        "        # MultivariateNormalDiag layer\n",
        "        distribution_params = tf.keras.layers.Concatenate()([mean, variance])\n",
        "        distribution = tfp.layers.DistributionLambda(\n",
        "            make_distribution_fn=lambda t: tfd.MultivariateNormalDiag(\n",
        "                loc=t[..., :1],\n",
        "                scale_diag=tf.math.softplus(t[..., 1:]) + tf.keras.backend.epsilon()\n",
        "            )\n",
        "        )(distribution_params)\n",
        "\n",
        "        return Model(inputs=inputs, outputs=distribution)\n",
        "\n",
        "    def estimate(self, workload_metrics):\n",
        "        # Estimate CPU utilization\n",
        "        return self.model.predict(workload_metrics)\n",
        "\n",
        "# Usage\n",
        "input_dim = 20  # As per the feature embedding dimension mentioned in the paper\n",
        "hidden_dim = 128  # This can be tuned\n",
        "\n",
        "estimator = CPUUtilizationEstimator(input_dim, hidden_dim)\n",
        "workload_metrics = np.array(scaled_features)  # Placeholder for workload metrics input\n",
        "estimated_cpu_utilization = estimator.estimate(workload_metrics)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss_fn = lambda y, model: -model.log_prob(y)\n",
        "target = df['cpu_utilization']\n",
        "X = scaler.fit_transform(df[['providerrpc_rt',\n",
        "       'providerrpc_mcr', 'consumerrpc_rt', 'consumerrpc_mcr', 'writemc_rt',\n",
        "       'writemc_mcr', 'readmc_rt', 'readmc_mcr', 'writedb_rt', 'writedb_mcr',\n",
        "       'readdb_rt', 'readdb_mcr', 'consumermq_rt', 'consumermq_mcr',\n",
        "       'providermq_rt', 'providermq_mcr', 'http_mcr', 'http_rt',\n",
        "       'cpu_utilization', 'memory_utilization']])\n",
        "y = target.values\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train.astype(np.float32), y_train.astype(np.float32))).batch(32)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val.astype(np.float32), y_val.astype(np.float32))).batch(32)\n",
        "\n",
        "# Training Loop\n",
        "epochs = 10  # Number of epochs\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "    # Training\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = estimator.model(x_batch_train, training=True)\n",
        "            y_batch_train_reshaped = tf.reshape(y_batch_train, [-1, 1])\n",
        "\n",
        "            loss_value = loss_fn(y_batch_train_reshaped, logits)\n",
        "        grads = tape.gradient(loss_value, estimator.model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, estimator.model.trainable_weights))\n",
        "\n",
        "        if step % 200 == 0:\n",
        "            loss_value_mean = tf.reduce_mean(loss_value)\n",
        "            print(\"Training loss (for one batch) at step %d: %.4f\" % (step, loss_value_mean))\n",
        "\n",
        "\n",
        "    # Validation\n",
        "    val_loss = []\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        val_logits = estimator.model(x_batch_val, training=False)\n",
        "\n",
        "        # Reshape y_batch_val to match val_logits shape\n",
        "        y_batch_val_reshaped = tf.reshape(y_batch_val, [-1, 1])\n",
        "\n",
        "        val_loss_value = loss_fn(y_batch_val_reshaped, val_logits)\n",
        "        val_loss_value_mean = tf.reduce_mean(val_loss_value)\n",
        "        val_loss.append(val_loss_value_mean)\n",
        "\n",
        "    val_loss_mean = np.mean(val_loss)\n",
        "    print(\"Validation loss: %.4f\" % val_loss_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "-CRTJS7rSDDu",
        "outputId": "7d496e0c-d462-4778-ae2f-c135e11f585e"
      },
      "outputs": [],
      "source": [
        "# eval_df =\n",
        "# eval_features = eval_df[['providerrpc_rt',\n",
        "#        'providerrpc_mcr', 'consumerrpc_rt', 'consumerrpc_mcr', 'writemc_rt',\n",
        "#        'writemc_mcr', 'readmc_rt', 'readmc_mcr', 'writedb_rt', 'writedb_mcr',\n",
        "#        'readdb_rt', 'readdb_mcr', 'consumermq_rt', 'consumermq_mcr',\n",
        "#        'providermq_rt', 'providermq_mcr', 'http_mcr', 'http_rt',\n",
        "#        'cpu_utilization', 'memory_utilization']]\n",
        "# eval_target = eval_df['cpu_utilization']\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# X_eval = scaler.fit_transform(eval_features)\n",
        "# y_eval = eval_target.values\n",
        "X_eval = X_val\n",
        "y_eval = y_val\n",
        "# If your model is saved, load it\n",
        "# model = tf.keras.models.load_model('path_to_your_model')\n",
        "\n",
        "# If the model is still in memory\n",
        "# Use the 'estimator' object directly\n",
        "\n",
        "# Convert to TensorFlow tensor and reshape target if needed\n",
        "X_eval = tf.convert_to_tensor(X_eval, dtype=tf.float32)\n",
        "y_eval_reshaped = tf.reshape(y_eval, [-1, 1])\n",
        "\n",
        "# Make predictions\n",
        "predictions = estimator.model(X_eval)\n",
        "predicted_cpu_utilization = predictions.mean()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "mae = tf.keras.losses.MeanAbsoluteError()\n",
        "\n",
        "mse_value = mse(y_eval_reshaped, predicted_cpu_utilization)\n",
        "mae_value = mae(y_eval_reshaped, predicted_cpu_utilization)\n",
        "\n",
        "print(\"Mean Squared Error on Evaluation Data:\", mse_value.numpy())\n",
        "print(\"Mean Absolute Error on Evaluation Data:\", mae_value.numpy())\n",
        "\n",
        "# Optional: Visualization of predictions vs actual values\n",
        "# This is helpful if you want to see how well the model predictions match the actual data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_eval, label='Actual CPU Utilization')\n",
        "plt.plot(predicted_cpu_utilization.numpy(), label='Predicted CPU Utilization')\n",
        "plt.title('CPU Utilization: Actual vs Predicted')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('CPU Utilization')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL0-gzmqlwzY",
        "outputId": "fc054a6e-8737-4d16-d410-2ba0c878fd10"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "iBwSN3BPnxgy",
        "outputId": "a9a1ac57-a76f-404d-f1e2-db304ab817d1"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "A7CMpmN_qF7f",
        "outputId": "8d7e7aff-c0c9-476f-eabf-f4912ca896af"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "def _plot_series(series, series_name, series_index=0):\n",
        "  from matplotlib import pyplot as plt\n",
        "  import seaborn as sns\n",
        "  palette = list(sns.palettes.mpl_palette('Dark2'))\n",
        "  xs = series['timestamp']\n",
        "  ys = series['providerrpc_rt']\n",
        "\n",
        "  plt.plot(xs, ys, label=series_name, color=palette[series_index % len(palette)])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')\n",
        "df_sorted = _df_8.sort_values('timestamp', ascending=True)\n",
        "_plot_series(df_sorted, '')\n",
        "sns.despine(fig=fig, ax=ax)\n",
        "plt.xlabel('timestamp')\n",
        "_ = plt.ylabel('providerrpc_rt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "csEUHVezn8mU",
        "outputId": "70e87de7-59fb-485a-dfeb-08d12a0ed79d"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "_df_15['consumerrpc_rt'].plot(kind='line', figsize=(8, 4), title='consumerrpc_rt')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X69za-vCn0Cm"
      },
      "outputs": [],
      "source": [
        "num_features = 20  # Number of workload metrics\n",
        "num_graph_nodes = 17303  # Number of nodes in your graph\n",
        "seq_length = 30  # Length of the temporal sequence\n",
        "\n",
        "def create_stgnn_model(num_features, num_graph_nodes, seq_length):\n",
        "    # Input for Graph Structure and Node Features\n",
        "    A = Input(shape=(num_graph_nodes, num_graph_nodes))  # Adjacency matrix\n",
        "    X = Input(shape=(seq_length, num_graph_nodes, num_features))  # Node features (time-series data)\n",
        "\n",
        "    # Process Node Features\n",
        "    processed_features = TimeDistributed(Dense(32, activation='relu'))(X)\n",
        "    processed_features = tf.reduce_mean(processed_features, axis=1)  # Example aggregation\n",
        "\n",
        "    # Graph Convolution Layer\n",
        "    graph_conv_output = GCNConv(32, activation='relu')([processed_features, A])\n",
        "\n",
        "    # Temporal Convolution Layer\n",
        "    temporal_conv_output = Conv1D(filters=16, kernel_size=3, activation='relu')(graph_conv_output)\n",
        "    temporal_conv_output = LayerNormalization()(temporal_conv_output)\n",
        "\n",
        "    # LSTM Layer for Temporal Dependencies\n",
        "    lstm_output = LSTM(64, return_sequences=False)(temporal_conv_output)\n",
        "\n",
        "    # Output Layer\n",
        "    output = Dense(1)(lstm_output)\n",
        "\n",
        "    return Model(inputs=[X, A], outputs=output)\n",
        "\n",
        "# Example usage\n",
        "\n",
        "\n",
        "model = create_stgnn_model(num_features, num_graph_nodes, seq_length)\n",
        "model.compile(optimizer='adam', loss='mse')  # Adjust based on your needs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uybtb_uIeC0f"
      },
      "outputs": [],
      "source": [
        "num_nodes = 10  # Assuming you have 10 nodes\n",
        "A = np.eye(num_nodes)  # Identity matrix as a placeholder\n",
        "\n",
        "# Extract and organize node features\n",
        "# Assuming your features are already in the correct format\n",
        "features = ['providerrpc_rt',\n",
        "       'providerrpc_mcr', 'consumerrpc_rt', 'consumerrpc_mcr', 'writemc_rt',\n",
        "       'writemc_mcr', 'readmc_rt', 'readmc_mcr', 'writedb_rt', 'writedb_mcr',\n",
        "       'readdb_rt', 'readdb_mcr', 'consumermq_rt', 'consumermq_mcr',\n",
        "       'providermq_rt', 'providermq_mcr', 'http_mcr', 'http_rt',\n",
        "       'cpu_utilization', 'memory_utilization']  # Adjust this based on your actual data columns\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(df[['providerrpc_rt',\n",
        "       'providerrpc_mcr', 'consumerrpc_rt', 'consumerrpc_mcr', 'writemc_rt',\n",
        "       'writemc_mcr', 'readmc_rt', 'readmc_mcr', 'writedb_rt', 'writedb_mcr',\n",
        "       'readdb_rt', 'readdb_mcr', 'consumermq_rt', 'consumermq_mcr',\n",
        "       'providermq_rt', 'providermq_mcr', 'http_mcr', 'http_rt',\n",
        "       'cpu_utilization', 'memory_utilization']])\n",
        "\n",
        "# Reshape features to match the input shape expected by the model\n",
        "# Adjust 'num_graph_nodes' and 'seq_length' based on your data\n",
        "num_features = len(features)\n",
        "\n",
        "# You need to define seq_length and num_graph_nodes based on your dataset's structure\n",
        "seq_length = 1  # For instance, 30 time steps per node\n",
        "num_graph_nodes = int((18497 * num_features) / (seq_length * num_features))  # Calculate number of nodes\n",
        "\n",
        "# Verify if the reshaping is feasible\n",
        "total_elements = 18497 * num_features\n",
        "required_elements = seq_length * num_graph_nodes * num_features\n",
        "\n",
        "\n",
        "print(total_elements,required_elements)\n",
        "if total_elements != required_elements:\n",
        "    raise ValueError(\"Cannot reshape: The total number of elements doesn't match the target shape.\")\n",
        "\n",
        "X_reshaped = X.reshape(num_features,num_graph_nodes,)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "\n",
        "X_train, X_val,y_train, y_val= train_test_split(X_reshaped, X_reshaped, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeK28-9Hi8-o",
        "outputId": "31ceada3-5e00-4e56-e0dd-83217a2a2bf9"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHdaVIIcjAYK",
        "outputId": "1faa844e-5e2a-4203-8be5-b8333c2d8d69"
      },
      "outputs": [],
      "source": [
        "X_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DU1D2eU3i3m",
        "outputId": "bf506b03-edae-47d4-8910-c2afb9051665"
      },
      "outputs": [],
      "source": [
        "len(df['msinstanceid'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "JC9BT9gETKki",
        "outputId": "ac130aad-b2a1-417e-a599-956c026e0ed5"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8so_lFeOezBp",
        "outputId": "219aa340-97cc-415c-e53c-b846c80955ce"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7ju0O3ce1g8"
      },
      "outputs": [],
      "source": [
        "new_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nPhxaurfPmu"
      },
      "outputs": [],
      "source": [
        "new_df['msinstanceid'] = df['msinstanceid'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHqG2M6AfYLz"
      },
      "outputs": [],
      "source": [
        "new_df.to_csv('ReqMSInstanceIDs.csv')\n",
        "combinedDf = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AihpC1ofmuyp",
        "outputId": "f7ff4f74-7822-40ce-b808-a98cd26ce286"
      },
      "outputs": [],
      "source": [
        "msInstaces = []\n",
        "msInstaces = df['msinstanceid']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G79oMy5emu2C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alvQybjqfZkN"
      },
      "outputs": [],
      "source": [
        "call_df0 = pd.read_csv('CallGraph_0.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxnhFfwsnSRB",
        "outputId": "061542eb-88b2-485f-d012-844cc450ae85"
      },
      "outputs": [],
      "source": [
        "filtered_df = df_data[call_df0['dminstance'].isin(df_msInstance['msInstance']) & df_data['uminstance'].isin(df_msInstance['msInstance'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klb8pmDmtujB"
      },
      "outputs": [],
      "source": [
        "call_df0.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkH8dHYyukfo"
      },
      "outputs": [],
      "source": [
        "call_df = pd.read_csv(\"FinalCombinedDf.csv\")\n",
        "reqMS_df = pd.read_csv(\"ReqMSInstanceIDs.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDrh1cShvdXS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPvrHzqltA7L",
        "outputId": "de40d737-b7fc-4e4f-c533-021eed7211bb"
      },
      "outputs": [],
      "source": [
        "(call_df['uminstanceid'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5UbgbVwtC3H",
        "outputId": "018ad4eb-23ce-4552-eee8-a097a482d2ba"
      },
      "outputs": [],
      "source": [
        "(call_df['dminstanceid'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF5uEaO3vc80",
        "outputId": "87eeaaec-d71e-4c97-b408-8c2e0bcb566b"
      },
      "outputs": [],
      "source": [
        "reqMS_df['msinstanceid']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdkZDWiM6_f6",
        "outputId": "f238ba8e-35c8-4296-c527-0873c818755a"
      },
      "outputs": [],
      "source": [
        "len(input_features),len(df),X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "1L0viFI96_64",
        "outputId": "247efa49-9c7a-43e4-dec6-6cfd3db7c868"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(-1, seq_length, num_features)\n",
        "X_val = X_val.reshape(-1, seq_length, num_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNu22GhN7Ats",
        "outputId": "fa50f041-b7d4-4b73-bcaa-c4f2b2b57a8d"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlszSyGpOCAw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Assuming you have a Pandas DataFrame called 'df' with your dataset\n",
        "\n",
        "# Sort the DataFrame by timestamp\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "df = df.sort_values(by=['timestamp'])\n",
        "\n",
        "# Assuming 'timestamp' is in datetime format, you can calculate the time difference between consecutive timestamps\n",
        "df['time_diff'] = (df['timestamp'] - df['timestamp'].shift(1)).dt.total_seconds().fillna(0)\n",
        "\n",
        "# Define the STGNN model\n",
        "class STGNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(STGNN, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)  # Update output_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        \n",
        "        # Depending on the LSTM configuration, out may have two or three dimensions\n",
        "        if len(out.shape) == 3:\n",
        "            out = self.fc(out[:, -1, :])\n",
        "        else:\n",
        "            out = self.fc(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X = torch.tensor(df[['providerrpc_rt', 'providerrpc_mcr', 'consumerrpc_rt', 'consumerrpc_mcr',\n",
        "                     'writemc_rt', 'writemc_mcr', 'readmc_rt', 'readmc_mcr',\n",
        "                     'writedb_rt', 'writedb_mcr', 'readdb_rt', 'readdb_mcr',\n",
        "                     'consumermq_rt', 'consumermq_mcr', 'providermq_rt', 'providermq_mcr',\n",
        "                     'http_mcr', 'http_rt']].values, dtype=torch.float32)\n",
        "y = torch.tensor(df[['providerrpc_rt', 'providerrpc_mcr', 'consumerrpc_rt', 'consumerrpc_mcr',\n",
        "                     'writemc_rt', 'writemc_mcr', 'readmc_rt', 'readmc_mcr',\n",
        "                     'writedb_rt', 'writedb_mcr', 'readdb_rt', 'readdb_mcr',\n",
        "                     'consumermq_rt', 'consumermq_mcr', 'providermq_rt', 'providermq_mcr',\n",
        "                     'http_mcr', 'http_rt']].values, dtype=torch.float32)  # Change the target metric as needed\n",
        "\n",
        "# Create a DataLoader\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert back to PyTorch tensors\n",
        "X_train, X_test, y_train, y_test = map(torch.tensor, (X_train, X_test, y_train, y_test))\n",
        "\n",
        "# Create a DataLoader for training and testing sets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_loss = 0.0\n",
        "        for inputs, labels in test_dataloader:\n",
        "            outputs = model(inputs)\n",
        "            test_loss += criterion(outputs, labels).item()\n",
        "\n",
        "        average_test_loss = test_loss / len(test_dataloader)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {loss.item()}, Test Loss: {average_test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have already defined your model, criterion, and optimizer\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X = torch.tensor(df[['providerrpc_rt', 'providerrpc_mcr', 'consumerrpc_rt', 'consumerrpc_mcr',\n",
        "                     'writemc_rt', 'writemc_mcr', 'readmc_rt', 'readmc_mcr',\n",
        "                     'writedb_rt', 'writedb_mcr', 'readdb_rt', 'readdb_mcr',\n",
        "                     'consumermq_rt', 'consumermq_mcr', 'providermq_rt', 'providermq_mcr',\n",
        "                     'http_mcr', 'http_rt']].values, dtype=torch.float32)\n",
        "\n",
        "# Include all metric columns in the target variable 'y'\n",
        "# y = torch.tensor(df[['providerrpc_rt', 'providerrpc_mcr', 'consumerrpc_rt', 'consumerrpc_mcr',\n",
        "#                      'writemc_rt', 'writemc_mcr', 'readmc_rt', 'readmc_mcr',\n",
        "#                      'writedb_rt', 'writedb_mcr', 'readdb_rt', 'readdb_mcr',\n",
        "#                      'consumermq_rt', 'consumermq_mcr', 'providermq_rt', 'providermq_mcr',\n",
        "#                      'http_mcr', 'http_rt']].values, dtype=torch.float32)\n",
        "y = torch.tensor(df[['providerrpc_rt']].values, dtype=torch.float32)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert back to PyTorch tensors\n",
        "X_train, X_test, y_train, y_test = map(torch.tensor, (X_train, X_test, y_train, y_test))\n",
        "\n",
        "# Create a DataLoader for training and testing sets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "all_actual_values = []\n",
        "all_predicted_values = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_loss = 0.0\n",
        "        batch_actual_values = []\n",
        "        batch_predicted_values = []\n",
        "\n",
        "        for inputs, labels in test_dataloader:\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Store actual and predicted values for plotting\n",
        "            batch_actual_values.extend(labels.numpy())\n",
        "            batch_predicted_values.extend(outputs.numpy())\n",
        "\n",
        "            test_loss += criterion(outputs, labels).item()\n",
        "\n",
        "        average_test_loss = test_loss / len(test_dataloader)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {loss.item()}, Test Loss: {average_test_loss}')\n",
        "\n",
        "        # Store actual and predicted values for each epoch\n",
        "        all_actual_values.append(np.array(batch_actual_values))\n",
        "        all_predicted_values.append(np.array(batch_predicted_values))\n",
        "\n",
        "# Flatten the lists to get a single array for actual and predicted values\n",
        "print(len(actual_values))\n",
        "actual_values = np.concatenate(all_actual_values, axis=0)\n",
        "predicted_values = np.concatenate(all_predicted_values, axis=0)  # Flatten predicted values to 1D\n",
        "subsample_size = 100\n",
        "indices = np.random.choice(len(actual_values), size=subsample_size, replace=False)\n",
        "\n",
        "# Plot actual and predicted values as line graphs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(actual_values[indices], label='Actual', marker='o')\n",
        "plt.plot(predicted_values[indices], label='Predicted', marker='o')\n",
        "plt.title('Actual vs Predicted Values (Subsampled)')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Plot actual vs predicted values\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(actual_values, label='Actual', marker='o')\n",
        "# plt.plot(predicted_values, label='Predicted', marker='o', linestyle='--')\n",
        "# plt.title('Actual vs Predicted Values')\n",
        "# plt.xlabel('Index')\n",
        "# plt.ylabel('Values')\n",
        "# plt.legend()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'timestamp' is in a string format that can be parsed\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "# Sort the DataFrame by timestamp\n",
        "df = df.sort_values(by=['timestamp'])\n",
        "\n",
        "# Calculate the time difference between consecutive timestamps\n",
        "df['time_diff'] = (df['timestamp'] - df['timestamp'].shift(1)).dt.total_seconds().fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Assuming you have a Pandas DataFrame called 'df' with your dataset\n",
        "\n",
        "# Sort the DataFrame by timestamp\n",
        "\n",
        "# Assuming 'timestamp' is in datetime format, you can calculate the time difference between consecutive timestamps\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "# Sort the DataFrame by timestamp\n",
        "df = df.sort_values(by=['timestamp'])\n",
        "\n",
        "# Calculate the time difference between consecutive timestamps\n",
        "df['time_diff'] = (df['timestamp'] - df['timestamp'].shift(1)).dt.total_seconds().fillna(0)\n",
        "\n",
        "# Define the STGNN model\n",
        "class STGNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(STGNN, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        \n",
        "        # Depending on the LSTM configuration, out may have two or three dimensions\n",
        "        if len(out.shape) == 3:\n",
        "            out = self.fc(out[:, -1, :])\n",
        "        else:\n",
        "            out = self.fc(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X = torch.tensor(df[['time_diff','providerrpc_rt', 'providerrpc_mcr', 'consumerrpc_rt', 'consumerrpc_mcr',\n",
        "                     'writemc_rt', 'writemc_mcr', 'readmc_rt', 'readmc_mcr',\n",
        "                     'writedb_rt', 'writedb_mcr', 'readdb_rt', 'readdb_mcr',\n",
        "                     'consumermq_rt', 'consumermq_mcr', 'providermq_rt', 'providermq_mcr',\n",
        "                     'http_mcr', 'http_rt']].values, dtype=torch.float32)\n",
        "y = torch.tensor(df[['providerrpc_rt']].values, dtype=torch.float32)  # Change the target metric as needed\n",
        "\n",
        "# Create a DataLoader\n",
        "dataset = TensorDataset(X, y)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Instantiate the model, loss function, and optimizer\n",
        "model = STGNN(input_size=X.shape[1], hidden_size=64, output_size=1)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "# Now you can use the trained model to make predictions for the next timestamp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have already defined your model, criterion, and optimizer\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X = torch.tensor(df[['time_diff','providerrpc_rt', 'providerrpc_mcr', 'consumerrpc_rt', 'consumerrpc_mcr',\n",
        "                     'writemc_rt', 'writemc_mcr', 'readmc_rt', 'readmc_mcr',\n",
        "                     'writedb_rt', 'writedb_mcr', 'readdb_rt', 'readdb_mcr',\n",
        "                     'consumermq_rt', 'consumermq_mcr', 'providermq_rt', 'providermq_mcr',\n",
        "                     'http_mcr', 'http_rt']].values, dtype=torch.float32)\n",
        "\n",
        "# Include all metric columns in the target variable 'y'\n",
        "# y = torch.tensor(df[['providerrpc_rt', 'providerrpc_mcr', 'consumerrpc_rt', 'consumerrpc_mcr',\n",
        "#                      'writemc_rt', 'writemc_mcr', 'readmc_rt', 'readmc_mcr',\n",
        "#                      'writedb_rt', 'writedb_mcr', 'readdb_rt', 'readdb_mcr',\n",
        "#                      'consumermq_rt', 'consumermq_mcr', 'providermq_rt', 'providermq_mcr',\n",
        "#                      'http_mcr', 'http_rt']].values, dtype=torch.float32)\n",
        "y = torch.tensor(df[['providerrpc_rt']].values, dtype=torch.float32)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert back to PyTorch tensors\n",
        "X_train, X_test, y_train, y_test = map(torch.tensor, (X_train, X_test, y_train, y_test))\n",
        "\n",
        "# Create a DataLoader for training and testing sets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 100\n",
        "all_actual_values = []\n",
        "all_predicted_values = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_loss = 0.0\n",
        "        batch_actual_values = []\n",
        "        batch_predicted_values = []\n",
        "\n",
        "        for inputs, labels in test_dataloader:\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Store actual and predicted values for plotting\n",
        "            batch_actual_values.extend(labels.numpy())\n",
        "            batch_predicted_values.extend(outputs.numpy())\n",
        "\n",
        "            test_loss += criterion(outputs, labels).item()\n",
        "\n",
        "        average_test_loss = test_loss / len(test_dataloader)\n",
        "        # print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {loss.item()}, Test Loss: {average_test_loss}')\n",
        "\n",
        "        # Store actual and predicted values for each epoch\n",
        "        all_actual_values.append(np.array(batch_actual_values))\n",
        "        all_predicted_values.append(np.array(batch_predicted_values))\n",
        "\n",
        "# Flatten the lists to get a single array for actual and predicted values\n",
        "print(len(actual_values))\n",
        "actual_values = np.concatenate(all_actual_values, axis=0)\n",
        "predicted_values = np.concatenate(all_predicted_values, axis=0)  # Flatten predicted values to 1D\n",
        "subsample_size = 100\n",
        "indices = np.random.choice(len(actual_values), size=subsample_size, replace=False)\n",
        "\n",
        "# Plot actual and predicted values as line graphs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(actual_values[indices], label='Actual', marker='o')\n",
        "plt.plot(predicted_values[indices], label='Predicted', marker='o')\n",
        "plt.title('Actual vs Predicted Values (Subsampled)')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Plot actual vs predicted values\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(actual_values, label='Actual', marker='o')\n",
        "# plt.plot(predicted_values, label='Predicted', marker='o', linestyle='--')\n",
        "# plt.title('Actual vs Predicted Values')\n",
        "# plt.xlabel('Index')\n",
        "# plt.ylabel('Values')\n",
        "# plt.legend()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
